{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SVTvsH3T4x_A"
      },
      "outputs": [],
      "source": [
        "!pip install sdv pandas scikit-learn matplotlib seaborn\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "metadata": {
        "id": "EeA1Dd2L4_Rl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Load uploaded dataset\n",
        "df = pd.read_csv(\"creditcard.csv\")\n",
        "print(\"Shape:\", df.shape)\n",
        "\n",
        "# Scale Time and Amount\n",
        "scaler = StandardScaler()\n",
        "df[['Time', 'Amount']] = scaler.fit_transform(df[['Time', 'Amount']])\n",
        "\n",
        "# Split train/test\n",
        "train_df, test_df = train_test_split(df, test_size=0.20, random_state=42, stratify=df['Class'])\n",
        "\n",
        "print(\"Train shape:\", train_df.shape)\n",
        "print(\"Test shape:\", test_df.shape)\n"
      ],
      "metadata": {
        "id": "VCMwniXn8cXG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sdv.metadata import SingleTableMetadata\n",
        "from sdv.single_table import CTGANSynthesizer\n",
        "import time\n",
        "\n",
        "# Auto-detect metadata\n",
        "metadata = SingleTableMetadata()\n",
        "metadata.detect_from_dataframe(data=train_df)\n",
        "\n",
        "# CTGAN synthesizer\n",
        "synthesizer = CTGANSynthesizer(metadata=metadata, epochs=100, batch_size=500, verbose=True)\n",
        "\n",
        "t0 = time.time()\n",
        "synthesizer.fit(train_df)\n",
        "print(\"Training finished in {:.1f} seconds\".format(time.time() - t0))\n",
        "\n",
        "# Generate synthetic\n",
        "synthetic = synthesizer.sample(num_rows=len(train_df))\n",
        "print(\"Generated synthetic shape:\", synthetic.shape)\n",
        "\n",
        "# Preview synthetic\n",
        "synthetic.head()\n"
      ],
      "metadata": {
        "id": "40AVJcbk8glB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "synthetic.to_csv(\"synthetic_train.csv\", index=False)\n",
        "from google.colab import files\n",
        "files.download(\"synthetic_train.csv\")\n"
      ],
      "metadata": {
        "id": "hTrSZVIDG8J9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Utility evaluation: train on REAL vs train on SYNTHETIC, test on REAL test set\n",
        "import pandas as pd\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report, roc_auc_score\n",
        "\n",
        "# Use the existing dataframes we already created in Colab\n",
        "real_train = train_df.copy()\n",
        "real_test = test_df.copy()\n",
        "synth_train = synthetic.copy()\n",
        "\n",
        "TARGET = \"Class\"\n",
        "\n",
        "# Prepare X/y\n",
        "X_real = real_train.drop(columns=[TARGET])\n",
        "y_real = real_train[TARGET].astype(int)\n",
        "\n",
        "X_test = real_test.drop(columns=[TARGET])\n",
        "y_test = real_test[TARGET].astype(int)\n",
        "\n",
        "X_synth = synth_train.drop(columns=[TARGET])\n",
        "y_synth = synth_train[TARGET].astype(int)\n",
        "\n",
        "def train_and_eval(X_train, y_train, X_test, y_test, label):\n",
        "    clf = RandomForestClassifier(n_estimators=200, random_state=42, n_jobs=-1)\n",
        "    clf.fit(X_train, y_train)\n",
        "    preds = clf.predict(X_test)\n",
        "    probas = clf.predict_proba(X_test)[:,1]\n",
        "    print(\"\\n Eval:\", label, \"\\n\")\n",
        "    print(classification_report(y_test, preds, digits=4))\n",
        "    print(\"ROC AUC: {:.4f}\".format(roc_auc_score(y_test, probas)))\n",
        "\n",
        "# 1) Train on real, test on real\n",
        "train_and_eval(X_real, y_real, X_test, y_test, \"Train on REAL\")\n",
        "\n",
        "# 2) Train on synthetic, test on real\n",
        "train_and_eval(X_synth, y_synth, X_test, y_test, \"Train on SYNTHETIC\")\n"
      ],
      "metadata": {
        "id": "UOIuwwXfbKc1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Workaround: generate synthetic pool and extract fraud (Class==1) samples\n",
        "import pandas as pd\n",
        "import math\n",
        "from time import time\n",
        "\n",
        "target_n = 2000   # how many fraud examples we want (adjustable)\n",
        "batch_size = 10000\n",
        "max_rounds = 25   # stop after this many batches to avoid infinite loops\n",
        "\n",
        "fraud_rows = []\n",
        "generated = 0\n",
        "t0 = time()\n",
        "\n",
        "for r in range(max_rounds):\n",
        "    batch = synthesizer.sample(num_rows=batch_size)\n",
        "    generated += len(batch)\n",
        "    # ensure 'Class' is present and integer-like\n",
        "    if 'Class' not in batch.columns:\n",
        "        print(\"ERROR: 'Class' column missing in generated data.\")\n",
        "        break\n",
        "    fraud_batch = batch[batch['Class'] == 1]\n",
        "    if len(fraud_batch) > 0:\n",
        "        fraud_rows.append(fraud_batch)\n",
        "    found = sum(len(df) for df in fraud_rows) if fraud_rows else 0\n",
        "    print(f\"Round {r+1}: generated {len(batch)}, found fraud so far: {found}\")\n",
        "    if found >= target_n:\n",
        "        break\n",
        "\n",
        "total_fraud = pd.concat(fraud_rows, ignore_index=True) if fraud_rows else pd.DataFrame(columns=batch.columns)\n",
        "total_fraud = total_fraud.head(target_n)  # trim to exact target\n",
        "print(\"\\n Result \")\n",
        "print(\"Total synthetic rows generated:\", generated)\n",
        "print(\"Total synthetic fraud rows collected:\", len(total_fraud))\n",
        "print(\"\\nFirst 5 fraud examples:\\n\")\n",
        "print(total_fraud.head().to_string(index=False))\n"
      ],
      "metadata": {
        "id": "Awy-F-jcv60s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Build hybrid training set: real negatives + synthetic fraud positives, then evaluate\n",
        "import pandas as pd\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report, roc_auc_score\n",
        "from sklearn.utils import shuffle\n",
        "import numpy as np\n",
        "\n",
        "# Use variables already in memory:\n",
        "# real_train, real_test, total_fraud (from previous step), synthetic (full pool)\n",
        "# If names differ, adapt them accordingly.\n",
        "\n",
        "# 1) get all real negative (Class==0) from real_train\n",
        "real_neg = real_train[real_train['Class'] == 0].copy()\n",
        "len_neg = len(real_neg)\n",
        "print(\"Real negatives (train):\", len_neg)\n",
        "\n",
        "# 2) use the synthetic fraud examples we collected (total_fraud). If you used a different var, replace it.\n",
        "synthetic_pos = total_fraud.copy()  # should contain 'Class'==1\n",
        "print(\"Synthetic fraud examples available:\", len(synthetic_pos))\n",
        "\n",
        "# If synthetic_pos has fewer rows than needed, we can sample with replacement; here we will use up to len_neg to avoid extreme imbalance\n",
        "# Choose number of positives to use (you can adjust). We'll use min(len_neg//50, len(synthetic_pos)) to create ~2% positives similar to original ratio.\n",
        "target_pos = min(max(len_neg // 50, len(synthetic_pos)), len(synthetic_pos))\n",
        "# Explanation: original fraud ratio ~0.17% -> len_neg//50 gives ~2% positives; adjust as needed.\n",
        "print(\"Using synthetic positives (target):\", target_pos)\n",
        "\n",
        "synthetic_pos_sample = synthetic_pos.sample(n=target_pos, replace=(target_pos > len(synthetic_pos)), random_state=42)\n",
        "\n",
        "# 3) build hybrid df: combine real_neg + synthetic_pos_sample\n",
        "hybrid_df = pd.concat([real_neg, synthetic_pos_sample], ignore_index=True)\n",
        "hybrid_df = shuffle(hybrid_df, random_state=42).reset_index(drop=True)\n",
        "\n",
        "print(\"Hybrid training shape (rows, cols):\", hybrid_df.shape)\n",
        "print(\"Hybrid class distribution:\\n\", hybrid_df['Class'].value_counts())\n",
        "\n",
        "# 4) train & evaluate\n",
        "X_h = hybrid_df.drop(columns=['Class'])\n",
        "y_h = hybrid_df['Class'].astype(int)\n",
        "\n",
        "X_test = real_test.drop(columns=['Class'])\n",
        "y_test = real_test['Class'].astype(int)\n",
        "\n",
        "clf = RandomForestClassifier(n_estimators=200, random_state=42, n_jobs=-1)\n",
        "clf.fit(X_h, y_h)\n",
        "preds = clf.predict(X_test)\n",
        "probas = clf.predict_proba(X_test)[:,1]\n",
        "\n",
        "print(\"\\nEval: Train on HYBRID (real negatives + synthetic positives)\\n\")\n",
        "print(classification_report(y_test, preds, digits=4))\n",
        "print(\"ROC AUC: {:.4f}\".format(roc_auc_score(y_test, probas)))\n"
      ],
      "metadata": {
        "id": "zUQVZ4t0xCWT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Rebuild hybrid set with higher proportion of synthetic frauds (~10% of negatives)\n",
        "target_pos = min(len(real_neg) // 10, len(synthetic_pos))  # ~22k frauds if available, but we only have 2000\n",
        "print(\"Using synthetic positives (target):\", target_pos)\n",
        "\n",
        "synthetic_pos_sample = synthetic_pos.sample(n=target_pos, replace=(target_pos > len(synthetic_pos)), random_state=42)\n",
        "\n",
        "hybrid_df2 = pd.concat([real_neg, synthetic_pos_sample], ignore_index=True)\n",
        "hybrid_df2 = shuffle(hybrid_df2, random_state=42).reset_index(drop=True)\n",
        "\n",
        "print(\"Hybrid2 training shape:\", hybrid_df2.shape)\n",
        "print(\"Class distribution:\\n\", hybrid_df2['Class'].value_counts())\n",
        "\n",
        "X_h2 = hybrid_df2.drop(columns=['Class'])\n",
        "y_h2 = hybrid_df2['Class'].astype(int)\n",
        "\n",
        "clf2 = RandomForestClassifier(n_estimators=200, random_state=42, n_jobs=-1)\n",
        "clf2.fit(X_h2, y_h2)\n",
        "preds2 = clf2.predict(X_test)\n",
        "probas2 = clf2.predict_proba(X_test)[:,1]\n",
        "\n",
        "print(\"\\n=== Eval: Train on HYBRID2 (more synthetic frauds) ===\\n\")\n",
        "print(classification_report(y_test, preds2, digits=4))\n",
        "print(\"ROC AUC: {:.4f}\".format(roc_auc_score(y_test, probas2)))\n"
      ],
      "metadata": {
        "id": "JH_TiXtf0Dvh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import json\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "\n",
        "os.makedirs(\"images\", exist_ok=True)\n",
        "\n",
        "# 1) Save distribution plots for each feature\n",
        "features_to_plot = [\"Amount\", \"V1\", \"V2\", \"V3\"]\n",
        "for feat in features_to_plot:\n",
        "    plt.figure(figsize=(8,4))\n",
        "    sns.kdeplot(train_df[feat], label=\"Real\", fill=True, alpha=0.4)\n",
        "    sns.kdeplot(synthetic[feat], label=\"Synthetic\", fill=True, alpha=0.4)\n",
        "    plt.title(f\"Distribution of {feat}: Real vs Synthetic\")\n",
        "    plt.legend()\n",
        "    plt.tight_layout()\n",
        "    fname = f\"images/dist_{feat}.png\"\n",
        "    plt.savefig(fname, dpi=180)\n",
        "    plt.close()\n",
        "    print(\"Saved:\", fname)\n",
        "\n",
        "# 2) Nearest-neighbor privacy distances\n",
        "real_no_class = real_train.drop(columns=['Class'])\n",
        "synth_no_class = synthetic.drop(columns=['Class'])\n",
        "\n",
        "nbrs = NearestNeighbors(n_neighbors=1, algorithm='auto').fit(real_no_class.values)\n",
        "distances, indices = nbrs.kneighbors(synth_no_class.values)\n",
        "distances = distances.ravel()\n",
        "\n",
        "metrics = {\n",
        "    \"nearest_neighbor\": {\n",
        "        \"min\": float(np.min(distances)),\n",
        "        \"25%\": float(np.percentile(distances, 25)),\n",
        "        \"median\": float(np.median(distances)),\n",
        "        \"mean\": float(np.mean(distances)),\n",
        "        \"75%\": float(np.percentile(distances, 75)),\n",
        "        \"max\": float(np.max(distances))\n",
        "    },\n",
        "    \"n_synthetic\": int(len(synth_no_class)),\n",
        "    \"n_real\": int(len(real_no_class))\n",
        "}\n",
        "\n",
        "# Save JSON metrics\n",
        "with open(\"images/privacy_metrics.json\", \"w\") as f:\n",
        "    json.dump(metrics, f, indent=2)\n",
        "print(\"Saved: images/privacy_metrics.json\")\n",
        "\n",
        "md_text = f\"\"\"## Privacy metrics (Nearest-neighbor distances)\n",
        "\n",
        "- Min: {metrics['nearest_neighbor']['min']:.4f}\n",
        "- 25%: {metrics['nearest_neighbor']['25%']:.4f}\n",
        "- Median: {metrics['nearest_neighbor']['median']:.4f}\n",
        "- Mean: {metrics['nearest_neighbor']['mean']:.4f}\n",
        "- 75%: {metrics['nearest_neighbor']['75%']:.4f}\n",
        "- Max: {metrics['nearest_neighbor']['max']:.4f}\n",
        "\"\"\"\n",
        "with open(\"images/privacy_metrics.md\", \"w\") as f:\n",
        "    f.write(md_text)\n",
        "print(\"Saved: images/privacy_metrics.md\")\n",
        "\n",
        "# 3) Save distances histogram\n",
        "plt.figure(figsize=(8,4))\n",
        "plt.hist(distances, bins=100, color=\"purple\", alpha=0.7)\n",
        "plt.title(\"Histogram of Syntheticâ†’Nearest Real Distance\")\n",
        "plt.xlabel(\"Distance\")\n",
        "plt.ylabel(\"Frequency\")\n",
        "plt.tight_layout()\n",
        "hist_fname = \"images/distance_histogram.png\"\n",
        "plt.savefig(hist_fname, dpi=180)\n",
        "plt.close()\n",
        "print(\"Saved:\", hist_fname)\n",
        "\n",
        "# 4)  Save small sample CSVs\n",
        "real_sample = real_train.sample(n=500, random_state=42)\n",
        "synth_sample = synthetic.sample(n=500, random_state=42)\n",
        "real_sample.to_csv(\"images/real_sample_500.csv\", index=False)\n",
        "synth_sample.to_csv(\"images/synth_sample_500.csv\", index=False)\n",
        "print(\"Saved: images/real_sample_500.csv and images/synth_sample_500.csv\")\n",
        "\n",
        "# 5) Print summary\n",
        "print(\"\\nSummary metrics:\")\n",
        "for k,v in metrics['nearest_neighbor'].items():\n",
        "    print(f\"{k}: {v:.4f}\")\n"
      ],
      "metadata": {
        "id": "SBtCpwpUMKTw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -r images.zip images\n",
        "from google.colab import files\n",
        "files.download(\"images.zip\")\n"
      ],
      "metadata": {
        "id": "h_-OfHBiOXyK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "YBQ-W5C-IFdk"
      }
    }
  ]
}